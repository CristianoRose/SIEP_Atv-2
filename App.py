import streamlit as st
import pandas as pd
import numpy as np
import statsmodels.api as sm
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from io import StringIO

# Configura√ß√£o da p√°gina
st.set_page_config(layout="wide", page_title="An√°lise Interativa de Regress√£o e ANOVA")

# Estilo CSS para melhorar a apar√™ncia (opcional)
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .sidebar .sidebar-content {
        background: #f0f2f6;
    }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 5px;
        padding: 10px 24px;
    }
    .stSelectbox, .stMultiselect {
        border-radius: 5px;
    }
</style>
""", unsafe_allow_html=True)

# --- Fun√ß√µes Auxiliares ---
@st.cache_data # Cache para otimizar o carregamento de dados
def load_data(uploaded_file):
    if uploaded_file is not None:
        try:
            # Tenta ler como CSV, que √© o formato esperado
            df = pd.read_csv(uploaded_file)
        except Exception as e:
            st.error(f"Erro ao carregar o arquivo: {e}")
            return None
    else: # Carrega o arquivo AmesHousing.csv por padr√£o se nenhum arquivo for enviado
        try:
            df = pd.read_csv("AmesHousing.csv")
        except FileNotFoundError:
            st.error("Arquivo AmesHousing.csv n√£o encontrado. Por favor, fa√ßa o upload ou coloque-o na pasta do app.")
            return None
    
    # Padroniza nomes das colunas
    df.columns = df.columns.str.strip().str.replace(" ", "_").str.lower()
    return df

def perform_anova(df_anova, categorical_var, target_var):
    st.subheader(f"An√°lise ANOVA: {target_var} por {categorical_var}")

    df_subset = df_anova[[categorical_var, target_var]].copy()
    df_subset.dropna(inplace=True)

    if df_subset.empty or df_subset[categorical_var].nunique() < 2:
        st.warning("Dados insuficientes ou poucas categorias para realizar ANOVA.")
        return

    # Boxplot
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.boxplot(x=categorical_var, y=target_var, data=df_subset, ax=ax, palette="viridis")
    ax.set_title(f'Pre√ßo de Venda por {categorical_var}')
    ax.set_xlabel(categorical_var)
    ax.set_ylabel(target_var)
    st.pyplot(fig)

    # Grupos para ANOVA
    groups = [group[target_var].values for name, group in df_subset.groupby(categorical_var)]

    # ANOVA
    if len(groups) >= 2: # ANOVA requer pelo menos 2 grupos
        f_statistic, p_value_anova = stats.f_oneway(*groups)
        st.markdown("### Resultados da ANOVA (One-Way)")
        st.write(f"**Estat√≠stica F:** {f_statistic:.4f}")
        st.write(f"**Valor-p:** {p_value_anova:.4g}")
        if p_value_anova < 0.05:
            st.success("H√° diferen√ßas estatisticamente significativas entre as m√©dias dos grupos.")
        else:
            st.info("N√£o h√° evid√™ncias de diferen√ßas estatisticamente significativas entre as m√©dias dos grupos.")

        # Verifica√ß√£o de Pressupostos
        st.markdown("### Verifica√ß√£o dos Pressupostos da ANOVA")
        
        # Modelo OLS para res√≠duos
        try:
            formula = f'`{target_var}` ~ C(`{categorical_var}`)' # Usar crases para nomes de colunas com caracteres especiais
            model_ols = sm.OLS.from_formula(formula, data=df_subset).fit()
            residuals = model_ols.resid

            # Normalidade dos Res√≠duos (Shapiro-Wilk)
            if len(residuals) >=3: # Shapiro-Wilk requer pelo menos 3 amostras
                shapiro_stat, shapiro_p = stats.shapiro(residuals)
                st.write(f"**Teste de Normalidade dos Res√≠duos (Shapiro-Wilk) - Valor-p:** {shapiro_p:.4g}")
                if shapiro_p < 0.05:
                    st.warning("Os res√≠duos n√£o seguem uma distribui√ß√£o normal.")
                else:
                    st.success("Os res√≠duos parecem seguir uma distribui√ß√£o normal.")
            else:
                st.warning("N√£o foi poss√≠vel realizar o teste de Shapiro-Wilk (poucos dados nos res√≠duos).")


            # Homocedasticidade (Levene)
            levene_stat, levene_p = stats.levene(*groups)
            st.write(f"**Teste de Homocedasticidade (Levene) - Valor-p:** {levene_p:.4g}")
            if levene_p < 0.05:
                st.warning("As vari√¢ncias dos grupos n√£o s√£o homog√™neas (heterocedasticidade).")
            else:
                st.success("As vari√¢ncias dos grupos parecem ser homog√™neas.")

            # Teste de Kruskal-Wallis (alternativa n√£o param√©trica)
            if shapiro_p < 0.05 or levene_p < 0.05:
                st.markdown("### Teste de Kruskal-Wallis (Alternativa N√£o Param√©trica)")
                kruskal_stat, kruskal_p = stats.kruskal(*groups)
                st.write(f"**Estat√≠stica H (Kruskal-Wallis):** {kruskal_stat:.4f}")
                st.write(f"**Valor-p:** {kruskal_p:.4g}")
                if kruskal_p < 0.05:
                    st.success("O teste de Kruskal-Wallis indica diferen√ßas significativas entre os grupos.")
                else:
                    st.info("O teste de Kruskal-Wallis n√£o indica diferen√ßas significativas entre os grupos.")
        except Exception as e:
            st.error(f"Erro ao verificar pressupostos ou rodar Kruskal-Wallis: {e}")
    else:
        st.warning("ANOVA requer pelo menos dois grupos para compara√ß√£o.")


def perform_regression(df_reg, explanatory_vars, target_var, apply_log_target, apply_log_continuous):
    st.subheader("An√°lise de Regress√£o Linear M√∫ltipla")

    cols_to_use = explanatory_vars + [target_var]
    df_model = df_reg[cols_to_use].copy()
    df_model.dropna(inplace=True)

    if df_model.shape[0] < len(explanatory_vars) + 2: # Verifica se h√° dados suficientes
        st.warning("Dados insuficientes ap√≥s remo√ß√£o de NaNs para construir o modelo.")
        return

    # Identificar vari√°veis categ√≥ricas e cont√≠nuas entre as explicativas
    categorical_explanatory = [col for col in explanatory_vars if df_model[col].dtype == 'object' or df_model[col].nunique() < 20] # Heur√≠stica para categ√≥ricas
    continuous_explanatory = [col for col in explanatory_vars if col not in categorical_explanatory]

    # Aplicar log na vari√°vel alvo
    y = df_model[target_var].astype(float)
    if apply_log_target:
        if (y <= 0).any():
            st.warning(f"A vari√°vel alvo '{target_var}' cont√©m valores n√£o positivos. Log n√£o aplicado.")
        else:
            y = np.log(y)
            st.info(f"Transforma√ß√£o logar√≠tmica aplicada √† vari√°vel alvo: '{target_var}'.")
    
    # Preparar X
    X_df = df_model[explanatory_vars].copy()

    # Aplicar log nas vari√°veis explicativas cont√≠nuas selecionadas
    if apply_log_continuous:
        for col in continuous_explanatory:
            if (X_df[col] <= 0).any():
                st.warning(f"Vari√°vel explicativa '{col}' cont√©m valores n√£o positivos. Log n√£o aplicado para esta coluna.")
            else:
                X_df[f'log_{col}'] = np.log(X_df[col])
                st.info(f"Transforma√ß√£o logar√≠tmica aplicada √† vari√°vel explicativa: '{col}'.")
        
        # Remover colunas originais que foram transformadas, exceto se forem dummies
        cols_to_drop_for_log = [col for col in continuous_explanatory if f'log_{col}' in X_df.columns]
        X_df.drop(columns=cols_to_drop_for_log, inplace=True)


    # Criar dummies para vari√°veis categ√≥ricas
    if categorical_explanatory:
        X_df = pd.get_dummies(X_df, columns=categorical_explanatory, drop_first=True, dtype=float)
    
    X_df = X_df.astype(float)
    X_with_const = sm.add_constant(X_df)

    # Ajustar modelo
    try:
        model = sm.OLS(y, X_with_const).fit()
        st.markdown("### Sum√°rio do Modelo de Regress√£o (OLS Results)")
        st.text(model.summary().as_text())

        # An√°lise de Res√≠duos
        st.markdown("### An√°lise de Res√≠duos")
        y_pred = model.predict(X_with_const)
        residuals = model.resid

        # Gr√°fico de Res√≠duos vs. Preditos
        fig, ax = plt.subplots(figsize=(10,6))
        sns.scatterplot(x=y_pred, y=residuals, ax=ax, color="royalblue", alpha=0.7)
        ax.axhline(0, color='red', linestyle='--')
        ax.set_xlabel('Valores Preditos')
        ax.set_ylabel('Res√≠duos')
        ax.set_title('Res√≠duos vs. Valores Preditos')
        st.pyplot(fig)
        
        # Testes de Pressupostos sobre os res√≠duos
        if len(residuals) >= 3: # Shapiro-Wilk requer pelo menos 3 amostras
            shapiro_stat, shapiro_p = stats.shapiro(residuals)
            st.write(f"**Teste de Normalidade dos Res√≠duos (Shapiro-Wilk) - Valor-p:** {shapiro_p:.4g}")
            if shapiro_p < 0.05:
                st.warning("Os res√≠duos n√£o parecem seguir uma distribui√ß√£o normal.")
            else:
                st.success("Os res√≠duos parecem seguir uma distribui√ß√£o normal.")
        else:
            st.warning("N√£o foi poss√≠vel realizar o teste de Shapiro-Wilk nos res√≠duos (poucos dados).")


        if X_with_const.shape[0] > X_with_const.shape[1]: # Breusch-Pagan precisa de mais observa√ß√µes que regressores
            try:
                bp_test_lm, bp_p_value, bp_f_stat, bp_f_p_value = sm.stats.het_breuschpagan(residuals, X_with_const)
                st.write(f"**Teste de Homocedasticidade (Breusch-Pagan) - Valor-p (LM-stat):** {bp_p_value:.4g}")
                if bp_p_value < 0.05:
                    st.warning("H√° evid√™ncia de heterocedasticidade (vari√¢ncias dos res√≠duos n√£o s√£o constantes).")
                else:
                    st.success("N√£o h√° evid√™ncia de heterocedasticidade.")
            except Exception as e_bp:
                 st.warning(f"N√£o foi poss√≠vel realizar o teste de Breusch-Pagan: {e_bp}")
        else:
            st.warning("N√£o foi poss√≠vel realizar o teste de Breusch-Pagan (dados insuficientes ou colinearidade perfeita).")


        # VIF
        st.markdown("### Verifica√ß√£o de Multicolinearidade (VIF)")
        if X_with_const.shape[1] > 1: # VIF requer mais de uma vari√°vel (al√©m da constante)
            vif_data = pd.DataFrame()
            vif_data["Vari√°vel"] = X_with_const.columns
            try:
                vif_data["VIF"] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]
                st.dataframe(vif_data.sort_values(by="VIF", ascending=False))
                if (vif_data["VIF"] > 10).any():
                    st.warning("Algumas vari√°veis apresentam VIF > 10, indicando poss√≠vel multicolinearidade.")
                elif (vif_data["VIF"] > 5).any():
                    st.warning("Algumas vari√°veis apresentam VIF > 5, indicando potencial multicolinearidade moderada.")
                else:
                    st.success("N√£o foram encontrados problemas graves de multicolinearidade (VIF < 5 para todas as vari√°veis explicativas).")

            except Exception as e_vif:
                 st.warning(f"N√£o foi poss√≠vel calcular o VIF para todas as vari√°veis (pode indicar colinearidade perfeita): {e_vif}")
        else:
            st.info("VIF n√£o aplic√°vel com menos de duas vari√°veis explicativas.")


        # M√©tricas de Desempenho
        st.markdown("### M√©tricas de Desempenho do Modelo")
        
        y_actual_for_metrics = y # J√° est√° em log se apply_log_target for True
        y_pred_for_metrics = y_pred # Predi√ß√µes tamb√©m est√£o na escala de y

        if apply_log_target: # Se log foi aplicado no alvo, reverter para escala original para m√©tricas interpret√°veis
            y_actual_for_metrics = np.exp(y)
            y_pred_for_metrics = np.exp(y_pred)
            st.info("M√©tricas RMSE e MAE calculadas na escala original da vari√°vel alvo (ap√≥s exp()). R¬≤ √© da escala ajustada (log).")
            r2_adjusted_scale = model.rsquared # R¬≤ do modelo na escala log
            r2_original_scale = r2_score(y_actual_for_metrics, y_pred_for_metrics) # R¬≤ na escala original
            st.write(f"**R¬≤ (na escala do modelo, {'logar√≠tmica' if apply_log_target else 'original'}):** {r2_adjusted_scale:.4f}")
            st.write(f"**R¬≤ (na escala original da vari√°vel alvo):** {r2_original_scale:.4f} (Comparativo)")
        else:
            r2 = model.rsquared
            st.write(f"**R¬≤:** {r2:.4f}")

        rmse = np.sqrt(mean_squared_error(y_actual_for_metrics, y_pred_for_metrics))
        mae = mean_absolute_error(y_actual_for_metrics, y_pred_for_metrics)
        st.write(f"**RMSE (Root Mean Squared Error):** {rmse:.2f}")
        st.write(f"**MAE (Mean Absolute Error):** {mae:.2f}")
        
        st.markdown("---")
        st.markdown("#### Interpreta√ß√£o Geral dos Coeficientes")
        st.write("Os coeficientes no sum√°rio do modelo indicam a mudan√ßa m√©dia na vari√°vel alvo para um aumento de uma unidade na vari√°vel explicativa, mantendo as outras constantes.")
        if apply_log_target and any(f'log_{col}' in X_with_const.columns for col in continuous_explanatory if apply_log_continuous):
            st.write("Para **vari√°veis explicativas cont√≠nuas transformadas com log (log_)**: Um aumento de 1% na vari√°vel explicativa est√° associado a uma mudan√ßa de (coeficiente * 100)% na vari√°vel alvo (se esta tamb√©m estiver em log). Se a vari√°vel alvo n√£o estiver em log, um aumento de 1% na explicativa leva a uma mudan√ßa de (coeficiente / 100) unidades na vari√°vel alvo.")
        elif apply_log_target:
             st.write("Para **vari√°veis explicativas cont√≠nuas (n√£o log)**: Um aumento de uma unidade na vari√°vel explicativa est√° associado a uma mudan√ßa de (coeficiente * 100)% na vari√°vel alvo (que est√° em log).")
        elif any(f'log_{col}' in X_with_const.columns for col in continuous_explanatory if apply_log_continuous):
            st.write("Para **vari√°veis explicativas cont√≠nuas transformadas com log (log_)**: Um aumento de 1% na vari√°vel explicativa est√° associado a uma mudan√ßa de (coeficiente / 100) unidades na vari√°vel alvo (que n√£o est√° em log).")

        st.write("Para **vari√°veis dummy (categ√≥ricas)**: O coeficiente representa a diferen√ßa m√©dia na vari√°vel alvo (ou log da vari√°vel alvo) entre a categoria representada pela dummy e a categoria base (omitida), mantendo as outras constantes.")


    except Exception as e:
        st.error(f"Erro ao ajustar o modelo de regress√£o: {e}")
        st.error("Verifique se as vari√°veis selecionadas s√£o apropriadas e se h√° dados suficientes.")
        st.error("Problemas comuns incluem colinearidade perfeita ou vari√°veis com vari√¢ncia zero.")

# --- Interface Principal do Streamlit ---
st.title("üìä Aplicativo Interativo de An√°lise de Dados")
st.markdown("Realize an√°lises de ANOVA e Regress√£o Linear de forma interativa.")

# Upload de arquivo
uploaded_file = st.sidebar.file_uploader("Carregue seu arquivo CSV", type=["csv"])
df = load_data(uploaded_file)

if df is not None:
    st.sidebar.success(f"Dados carregados com sucesso! ({df.shape[0]} linhas, {df.shape[1]} colunas)")
    
    analysis_type = st.sidebar.selectbox("Escolha o tipo de an√°lise:", ["ANOVA", "Regress√£o Linear"])

    if analysis_type == "ANOVA":
        st.sidebar.header("Op√ß√µes para ANOVA")
        
        numerical_cols_anova = df.select_dtypes(include=np.number).columns.tolist()
        categorical_cols_anova = df.select_dtypes(include='object').columns.tolist()
        
        if not categorical_cols_anova:
            st.error("Nenhuma coluna categ√≥rica encontrada no dataset para ANOVA.")
        elif not numerical_cols_anova:
            st.error("Nenhuma coluna num√©rica encontrada no dataset para ANOVA.")
        else:
            default_cat_anova = 'kitchen_qual' if 'kitchen_qual' in categorical_cols_anova else categorical_cols_anova[0]
            default_num_anova = 'saleprice' if 'saleprice' in numerical_cols_anova else numerical_cols_anova[0]

            categorical_var_anova = st.sidebar.selectbox("Selecione a vari√°vel categ√≥rica (grupos):", categorical_cols_anova, index=categorical_cols_anova.index(default_cat_anova) if default_cat_anova in categorical_cols_anova else 0)
            target_var_anova = st.sidebar.selectbox("Selecione a vari√°vel num√©rica (alvo):", numerical_cols_anova, index=numerical_cols_anova.index(default_num_anova) if default_num_anova in numerical_cols_anova else 0)

            if st.sidebar.button("Executar ANOVA", key="run_anova"):
                perform_anova(df, categorical_var_anova, target_var_anova)

    elif analysis_type == "Regress√£o Linear":
        st.sidebar.header("Op√ß√µes para Regress√£o Linear")
        
        all_cols_reg = df.columns.tolist()
        numerical_cols_reg = df.select_dtypes(include=np.number).columns.tolist()

        if not numerical_cols_reg:
             st.error("Nenhuma coluna num√©rica encontrada no dataset para ser a vari√°vel alvo da regress√£o.")
        else:
            default_target_reg = 'saleprice' if 'saleprice' in numerical_cols_reg else numerical_cols_reg[0]
            target_var_reg = st.sidebar.selectbox("Selecione a vari√°vel alvo (dependente):", numerical_cols_reg, index=numerical_cols_reg.index(default_target_reg) if default_target_reg in numerical_cols_reg else 0)
            
            available_explanatory = [col for col in all_cols_reg if col != target_var_reg]
            
            # Vari√°veis explicativas padr√£o baseadas no notebook, se existirem
            default_explanatory_vars = ['gr_liv_area', 'overall_qual', 'garage_finish', 'kitchen_qual', 'exter_qual', 'central_air']
            default_explanatory_vars_present = [var for var in default_explanatory_vars if var in available_explanatory]
            
            explanatory_vars_reg = st.sidebar.multiselect("Selecione as vari√°veis explicativas (independentes):", available_explanatory, default=default_explanatory_vars_present)

            apply_log_target_reg = st.sidebar.checkbox("Aplicar log na vari√°vel alvo?", value=True)
            
            continuous_for_log_selection = [col for col in explanatory_vars_reg if df[col].dtype in [np.number] and df[col].nunique() > 20] # Heur√≠stica para cont√≠nuas
            
            apply_log_continuous_reg = []
            if continuous_for_log_selection:
                 apply_log_continuous_reg_selection = st.sidebar.multiselect("Aplicar log em quais vari√°veis explicativas cont√≠nuas?", continuous_for_log_selection, default=[v for v in ['gr_liv_area', 'overall_qual'] if v in continuous_for_log_selection])
                 # O checkbox abaixo foi removido para dar controle mais granular com multiselect
                 # apply_log_continuous_reg = st.sidebar.checkbox("Aplicar log nas vari√°veis explicativas cont√≠nuas selecionadas?", value=True)
                 if apply_log_continuous_reg_selection: # Se o usu√°rio selecionou alguma
                    apply_log_continuous_reg = apply_log_continuous_reg_selection


            if st.sidebar.button("Executar Regress√£o", key="run_regression"):
                if not explanatory_vars_reg:
                    st.warning("Por favor, selecione pelo menos uma vari√°vel explicativa.")
                else:
                    # Passa a lista de colunas cont√≠nuas que devem ter log aplicado
                    continuous_to_log = [col for col in explanatory_vars_reg if col in apply_log_continuous_reg]
                    perform_regression(df, explanatory_vars_reg, target_var_reg, apply_log_target_reg, continuous_to_log)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("Desenvolvido com base no notebook fornecido.")

else:
    st.info("Aguardando o carregamento do arquivo de dados CSV...")
